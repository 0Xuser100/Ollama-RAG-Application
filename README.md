
---

# ğŸ’¡ LangChain Demo with Gemma Model

This project is a simple yet powerful Streamlit application demonstrating the integration of LangChain's capabilities with the **Gemma2 Llama model** for conversational AI. The app lets you interact with a helpful assistant capable of answering your questions dynamically and effectively.

---

## ğŸŒŸ Features
- **ğŸš€ Gemma2 Llama Model**: Powered by the **Gemma2:2b** model for generating precise and coherent responses.
- **ğŸ› ï¸ LangChain Integration**: Leverages LangChain's robust framework for building conversational AI pipelines.
- **ğŸ¯ Dynamic Prompting**: Uses a customizable prompt template for flexible responses.
- **ğŸ“ˆ Langsmith Tracking**: Includes tracking features for monitoring and evaluating performance.
- **ğŸ“¦ Streamlit Interface**: User-friendly interface for interactive question-answering.

---

## ğŸ”§ Prerequisites

To run this application, you'll need:
- **Python**: Version 3.7 or higher
- **LangChain API Key**: Required for tracking and project management
- **Streamlit**: For creating the web interface
- **Ollama**: For integrating the Gemma2 Llama model

---

## âš™ï¸ Installation

### 1. Clone the Repository
```bash
git clone https://github.com/0Xuser100/LangChain-Gemma-Demo.git
cd LangChain-Gemma-Demo
```

### 2. Create a Virtual Environment
```bash
python -m venv venv
```

### 3. Activate the Virtual Environment
- **Windows**:
  ```bash
  venv\Scripts\activate
  ```
- **macOS/Linux**:
  ```bash
  source venv/bin/activate
  ```

### 4. Install Dependencies
```bash
pip install -r requirements.txt
```

### 5. Set Up Environment Variables
- Create a `.env` file in the project root.
- Add the following variables:
  ```plaintext
  LANGCHAIN_API_KEY=your_langchain_api_key
  LANGCHAIN_PROJECT=your_project_name
  ```

---

## ğŸš€ How to Use

1. **Run the Application**
   ```bash
   streamlit run app.py
   ```

2. **Enter Your Question**
   - Use the input field to type your question.
   - Press Enter, and the assistant will provide a response.

---

## ğŸ—‚ï¸ Project Structure
```
LangChain-Gemma-Demo/
â”œâ”€â”€ app.py             # Main application script
â”œâ”€â”€ requirements.txt   # Required dependencies
â”œâ”€â”€ .env.example       # Template for environment variables
â”œâ”€â”€ README.md          # Project documentation
â””â”€â”€ resources/         # Placeholder for additional resources
```

---

## ğŸ“‹ Dependencies

### Key Python Packages
- `streamlit`
- `langchain_community`
- `langchain_core`
- `ollama`
- `dotenv`

Ensure all required packages are included in `requirements.txt`.

---

## ğŸ§ª Example Workflow

1. **User**: "What is the capital of France?"
2. **App**: Calls the **Gemma2** model with the LangChain pipeline.
3. **Response**: "The capital of France is Paris."

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:
- Fork the repository.
- Create a feature branch.
- Submit a pull request with your changes.

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

---

## ğŸ“ Contact

For questions, suggestions, or feedback:
- **Name**: Mahmoud Abdelhamid  
- **Email**: [mahmoudabdulhamid22@gmail.com](mailto:mahmoudabdulhamid22@gmail.com)  
- **GitHub**: [https://github.com/0Xuser100](https://github.com/0Xuser100)  
- **LinkedIn**: [https://www.linkedin.com/in/mahmoud-abdulhamid-052244230/](https://www.linkedin.com/in/mahmoud-abdulhamid-052244230/)

---

Unleash the potential of conversational AI with LangChain and the Gemma2 Llama model! ğŸš€
